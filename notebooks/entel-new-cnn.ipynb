{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom warnings import filterwarnings\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import RobustScaler, normalize, LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n\nfilterwarnings('ignore')\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-14T18:05:19.535304Z","iopub.execute_input":"2022-08-14T18:05:19.535941Z","iopub.status.idle":"2022-08-14T18:05:19.547775Z","shell.execute_reply.started":"2022-08-14T18:05:19.535891Z","shell.execute_reply":"2022-08-14T18:05:19.546555Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    'TRAIN_PATH': '/kaggle/input/datathon-entel-2022-reto2/train.csv',\n    'TEST_PATH': '/kaggle/input/datathon-entel-2022-reto2/test.csv',\n    'SAMPLE_SUBMISSION': '/kaggle/input/datathon-entel-2022-reto2/test_sample.csv'\n}\n\ndf_train = pd.read_csv(CONFIG['TRAIN_PATH'])\ndf_test = pd.read_csv(CONFIG['TEST_PATH'])\ndf_sub = pd.read_csv(CONFIG['SAMPLE_SUBMISSION'])","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:19.562898Z","iopub.execute_input":"2022-08-14T18:05:19.564380Z","iopub.status.idle":"2022-08-14T18:05:22.444779Z","shell.execute_reply.started":"2022-08-14T18:05:19.564325Z","shell.execute_reply":"2022-08-14T18:05:22.443297Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"n = 10\nx_base = 100","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:22.447013Z","iopub.execute_input":"2022-08-14T18:05:22.447402Z","iopub.status.idle":"2022-08-14T18:05:22.453156Z","shell.execute_reply.started":"2022-08-14T18:05:22.447367Z","shell.execute_reply":"2022-08-14T18:05:22.451564Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def vol_col(x):\n    return np.sqrt(np.log(x).stack().apply(lambda x: x if str(x) != '-inf' else 0).unstack(level=1)).sum().to_dict()\n\ndef vol(x):\n    return np.sqrt(np.log(x).stack().apply(lambda x: x if str(x) != '-inf' else 0).unstack(level=1)).sum().fillna(0)\n\n\ndef get_value(df, col, exp, exp2):\n    return df[col].replace(df.groupby([col])[df.iloc[:, 5: 5 + 45].columns].agg(exp).agg(exp2, axis=1).to_dict())\n    \n    \ndef replace_value_count(df, col):\n    return df[col].replace(df[col].value_counts(normalize=True).to_dict())\n\n\ndef count_0_values(df):\n    return df.iloc[:, 5: n + 5].stack().apply(lambda x: 1 if x > 0 else 0).unstack(level=1).sum(axis=1)\n\n\ndef best_department(df):\n    return df.Z_DEPARTAMENTO.apply(lambda x: 1 if x  in ['d6c21b948958417ca98b682a573eb8aa1084b292d32f760f253ef53da13e5589'] else 0)\n\ndef best_sell_point(df):\n    return df.Z_PUNTO_VENTA.apply(lambda x: 1 if x in \n                                  ['da45328ba820604eb99694768f2a430cd933d161601dcb8491b4a9b555232c59',\n                                   'e1f2d2708f545ddc1d7266ba0cc5ccc88147b77fdf3450e68a974e93018ecf60'] else 0)","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:22.454894Z","iopub.execute_input":"2022-08-14T18:05:22.455429Z","iopub.status.idle":"2022-08-14T18:05:22.472282Z","shell.execute_reply.started":"2022-08-14T18:05:22.455377Z","shell.execute_reply":"2022-08-14T18:05:22.470841Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def featuring(df):\n    \n    df = pd.concat([df_train.iloc[:, :5], df], axis=1)\n    \n    diff = df.iloc[:, 5:].diff(1, axis=1).fillna(0).stack().reset_index(drop=True)\n    \n    lag1 = df.iloc[:, 5:].shift(1, axis=1).fillna(0).stack().reset_index(drop=True)\n    lag2 = df.iloc[:, 5:].shift(2, axis=1).fillna(0).stack().reset_index(drop=True)\n    lag3 = df.iloc[:, 5:].shift(3, axis=1).fillna(0).stack().reset_index(drop=True)\n    \n    zptm = df.groupby(['Z_PUNTO_VENTA'])[df.iloc[:, 5:].columns].transform('mean').stack().reset_index(drop=True)\n    zmod = df.groupby(['Z_MODELO'])[df.iloc[:, 5:].columns].transform('mean').stack().reset_index(drop=True)\n    zdep = df.groupby(['Z_DEPARTAMENTO'])[df.iloc[:, 5:].columns].transform('mean').stack().reset_index(drop=True)\n    zmar = df.groupby(['Z_MARCA'])[df.iloc[:, 5:].columns].transform('mean').stack().reset_index(drop=True)\n    zgam = df.groupby(['Z_GAMA'])[df.iloc[:, 5:].columns].transform('mean').stack().reset_index(drop=True)    \n    \n    df = df.iloc[:, 5:].stack().reset_index(drop=True)\n    \n    df = pd.concat([df, diff, zptm, zmod, zdep, zmar, zgam, lag1, lag2, lag3], axis=1)\n    \n    return df\n\ndef extra_featuring(df):\n    \n    df = pd.concat([df_train.iloc[:, :5], df], axis=1)\n        \n    df_z_punto_venta = df.groupby(['Z_PUNTO_VENTA'])[df.iloc[:, 5:].columns].transform('max')\n    df_z_modelo = df.groupby(['Z_MODELO'])[df.iloc[:, 5:].columns].transform('max')\n    df_z_gama = df.groupby(['Z_GAMA'])[df.iloc[:, 5:].columns].transform('max')\n    df_z_marca = df.groupby(['Z_MARCA'])[df.iloc[:, 5:].columns].transform('max')\n    df_z_departamento = df.groupby(['Z_DEPARTAMENTO'])[df.iloc[:, 5:].columns].transform('max')\n    \n    df_z_s_punto_venta = df.groupby(['Z_PUNTO_VENTA'])[df.iloc[:, 5:].columns].transform('sum')\n    df_z_s_modelo = df.groupby(['Z_MODELO'])[df.iloc[:, 5:].columns].transform('sum')\n    df_z_s_gama = df.groupby(['Z_GAMA'])[df.iloc[:, 5:].columns].transform('sum')\n    df_z_s_marca = df.groupby(['Z_MARCA'])[df.iloc[:, 5:].columns].transform('sum')\n    df_z_s_departamento = df.groupby(['Z_DEPARTAMENTO'])[df.iloc[:, 5:].columns].transform('sum')\n    \n    df_b_punto_venta = df['Z_PUNTO_VENTA'].apply(lambda x: 1 if x in \n                                                     ['da45328ba820604eb99694768f2a430cd933d161601dcb8491b4a9b555232c59',\n                                                      'e1f2d2708f545ddc1d7266ba0cc5ccc88147b77fdf3450e68a974e93018ecf60'] else 0)\n    df_b_departameto = df['Z_DEPARTAMENTO'].apply(lambda x: 1 if x  in \n                                                    ['d6c21b948958417ca98b682a573eb8aa1084b292d32f760f253ef53da13e5589'] else 0)\n    \n    Z_MARCA = df['Z_MARCA'].replace(df['Z_MARCA'].value_counts(normalize=True).to_dict())\n    Z_GAMA = df['Z_GAMA'].replace(df['Z_GAMA'].value_counts(normalize=True).to_dict())\n    Z_MODELO = df['Z_MODELO'].replace(df['Z_MODELO'].value_counts(normalize=True).to_dict())\n    Z_DEPARTAMENTO = df['Z_DEPARTAMENTO'].replace(df['Z_DEPARTAMENTO'].value_counts(normalize=True).to_dict())\n    Z_PUNTO_VENTA = df['Z_PUNTO_VENTA'].replace(df['Z_PUNTO_VENTA'].value_counts(normalize=True).to_dict())\n    \n    df_max = df.iloc[:, 5:].max(axis=1)\n    df_sum = df.iloc[:, 5:].sum(axis=1)\n    df_std = df.iloc[:, 5:].std(axis=1)\n    df_mean = df.iloc[:, 5:].mean(axis=1)\n        \n    df_total= df_sum.apply(lambda x: 1 if x > 0 else 0)\n    df_count = df.iloc[:, 5:].stack().apply(lambda x: x if x > 0 else np.nan).unstack(level=1).count(axis=1)\n    \n    df_z = pd.concat([df_z_punto_venta,\n                      df_z_modelo, \n                      df_z_gama,\n                      df_z_marca,\n                      df_z_departamento,\n                      \n                      df_z_s_punto_venta,\n                      df_z_s_modelo,\n                      df_z_s_gama,\n                      df_z_s_marca,\n                      df_z_s_departamento,\n\n                      df_b_punto_venta,\n                      df_b_departameto,\n                      \n                      Z_MARCA,\n                      Z_GAMA,\n                      Z_MODELO,\n                      Z_DEPARTAMENTO,\n                      Z_PUNTO_VENTA,\n                      \n                      df_max,\n                      df_sum,\n                      df_std,\n                      df_mean,\n                      \n                      df_total,\n                      df_count\n                     ], axis=1).T.reset_index(drop=True).T\n    \n    return df_z","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:22.476738Z","iopub.execute_input":"2022-08-14T18:05:22.477263Z","iopub.status.idle":"2022-08-14T18:05:22.508295Z","shell.execute_reply.started":"2022-08-14T18:05:22.477217Z","shell.execute_reply":"2022-08-14T18:05:22.506572Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"x_train = pd.concat([\n    featuring(df_train.iloc[:, 5:15]),\n    featuring(df_train.iloc[:, 15:25]),\n    featuring(df_train.iloc[:, 25:35]),\n    featuring(df_train.iloc[:, 35:45]),\n], axis=0).reset_index(drop=True)\n\n\nx_train_extra = pd.concat([\n    extra_featuring(df_train.iloc[:, 5:15]),\n    extra_featuring(df_train.iloc[:, 15:25]),\n    extra_featuring(df_train.iloc[:, 25:35]),\n    extra_featuring(df_train.iloc[:, 35:45]),\n], axis=0).reset_index(drop=True)\n\ny_train = pd.concat([\n    pd.DataFrame(df_train.iloc[:, 15:25].values),\n    pd.DataFrame(df_train.iloc[:, 25:35].values),\n    pd.DataFrame(df_train.iloc[:, 35:45].values),\n    pd.DataFrame(df_train.iloc[:, 45:55].values)\n], axis=0).reset_index(drop=True)\n\n\nx_test = featuring(df_train.iloc[:, 45:55])\nx_test_extra = extra_featuring(df_train.iloc[:, 45:55])","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:22.510284Z","iopub.execute_input":"2022-08-14T18:05:22.510995Z","iopub.status.idle":"2022-08-14T18:05:34.718650Z","shell.execute_reply.started":"2022-08-14T18:05:22.510939Z","shell.execute_reply":"2022-08-14T18:05:34.716925Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def data_sequence_to_models(): \n    \n    sc = RobustScaler()\n    _x_train = sc.fit_transform(x_train).reshape(-1, n, x_train.shape[-1])\n    _x_test = sc.transform(x_test).reshape(-1, n, x_test.shape[-1])\n    \n    return _x_train, _x_test\n\n\ndef data_extra_to_models(): \n    \n    sc = RobustScaler()\n    _x_train = sc.fit_transform(x_train_extra)\n    _x_test = sc.transform(x_test_extra)\n    \n    return _x_train, _x_test","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:34.720537Z","iopub.execute_input":"2022-08-14T18:05:34.720970Z","iopub.status.idle":"2022-08-14T18:05:34.728797Z","shell.execute_reply.started":"2022-08-14T18:05:34.720930Z","shell.execute_reply":"2022-08-14T18:05:34.727537Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"x_train_data, x_test_data = data_sequence_to_models()\nx_train_extra, x_test_extra = data_extra_to_models()\n\ny_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:34.730538Z","iopub.execute_input":"2022-08-14T18:05:34.731044Z","iopub.status.idle":"2022-08-14T18:05:37.666432Z","shell.execute_reply.started":"2022-08-14T18:05:34.730995Z","shell.execute_reply":"2022-08-14T18:05:37.665121Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(f'X TRAIN SHAPE: {x_train.shape}')\nprint(f'Y TRAIN SHAPE: {y_train.shape}')\nprint(f'X TEST SHAPE: {x_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:37.668546Z","iopub.execute_input":"2022-08-14T18:05:37.668996Z","iopub.status.idle":"2022-08-14T18:05:37.678690Z","shell.execute_reply.started":"2022-08-14T18:05:37.668942Z","shell.execute_reply":"2022-08-14T18:05:37.677121Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def CNN(l_features, l_extras_features):\n    \n    features = keras.layers.Input(shape=l_features)\n    tabular = keras.layers.Input(shape=l_extras_features)\n    \n    out_features = keras.layers.Conv1D(filters=64, kernel_size=2, padding=\"same\", activation='relu')(features)\n    out_features = keras.layers.Dropout(0.2)(out_features)\n    out_features = keras.layers.Conv1D(filters=32, kernel_size=2, padding=\"same\", activation='relu')(out_features)\n    out_features = keras.layers.Dropout(0.2)(out_features)\n    out_features = keras.layers.MaxPooling1D(pool_size=2)(out_features)\n    out_features = keras.layers.Flatten()(out_features)\n\n    out_features = keras.layers.Dense(50, activation='linear')(out_features)\n    out_features = keras.layers.Dropout(0.2)(out_features)\n    out_features = keras.layers.Dense(32, activation='linear')(out_features)\n    \n    for n_hidden in [512, 256, 128, 64, 32]:\n        out_tabular = keras.layers.Dense(n_hidden, activation='relu')(tabular)\n        out_tabular = keras.layers.BatchNormalization()(out_tabular)\n        out_tabular = keras.layers.Dropout(0.2)(out_tabular)\n\n    out = tf.keras.layers.Multiply()([out_features, out_tabular])\n    out = keras.layers.Dense(10, activation='relu')(out)\n\n    model = keras.Model(inputs = [features, tabular], outputs = out)\n    \n    mse = tf.keras.losses.MeanSquaredError()\n    rmse = tf.keras.metrics.RootMeanSquaredError()\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0004), loss=mse, metrics=[rmse])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:06:01.465804Z","iopub.execute_input":"2022-08-14T18:06:01.466334Z","iopub.status.idle":"2022-08-14T18:06:01.481011Z","shell.execute_reply.started":"2022-08-14T18:06:01.466289Z","shell.execute_reply":"2022-08-14T18:06:01.479670Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def training_LSTM():\n\n    EPOCH = 1000\n    BATCH_SIZE = 512\n\n    models = []\n\n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2022)\n    \n    y_group = pd.Series(y_train.sum(axis=1)).apply(lambda x:  x if x < 15 else 15).values\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(x_train_data, y_group)):\n\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n\n        X_train, X_valid = x_train_data[train_idx], x_train_data[val_idx]\n        x_t_extras, x_v_extras = x_train_extra[train_idx], x_train_extra[val_idx]\n        \n        Y_train, Y_valid = y_train[train_idx], y_train[val_idx]\n\n        l_fet = X_train.shape[-2:]\n        l_ext = x_t_extras.shape[-1]\n        \n        model = CNN(l_fet, l_ext)\n\n        es = keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error', \n                                           min_delta=1e-05,\n                                           patience=50,\n                                           verbose=1, \n                                           mode='min', \n                                           restore_best_weights=True)\n        plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_root_mean_squared_error',\n                                                    factor=0.1,\n                                                    patience=10,\n                                                    verbose=1,\n                                                    min_lr=5e-7, \n                                                    mode='min')\n\n        model.fit([X_train, x_t_extras], Y_train,\n                  validation_data=([X_valid, x_v_extras], Y_valid),\n                  epochs=EPOCH,\n                  batch_size=BATCH_SIZE,\n                  callbacks = [es, plateau],\n                  verbose=1)\n\n        eval_model(model, [X_valid, x_v_extras], Y_valid)\n\n        models.append(model)\n\n    return models\n\ndef eval_model(model, x_valid, y_valid):\n    preds = pd.DataFrame(np.round(model.predict(x_valid)).astype('int32')).stack().reset_index(drop=True)\n    y_valid = pd.DataFrame(y_valid).stack().reset_index(drop=True)\n    print(f' RMSE --> {mean_squared_error(y_valid, preds, squared=False)}')","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:06:01.770824Z","iopub.execute_input":"2022-08-14T18:06:01.771382Z","iopub.status.idle":"2022-08-14T18:06:01.786764Z","shell.execute_reply.started":"2022-08-14T18:06:01.771337Z","shell.execute_reply":"2022-08-14T18:06:01.785551Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"models = training_LSTM()","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:06:02.319210Z","iopub.execute_input":"2022-08-14T18:06:02.320583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds= []\n\nfor model in models:\n    _pred = model.predict([x_test_data])\n    preds.append(_pred)\n    \npred_sub = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4]) / 5","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:38.518271Z","iopub.status.idle":"2022-08-14T18:05:38.519030Z","shell.execute_reply.started":"2022-08-14T18:05:38.518774Z","shell.execute_reply":"2022-08-14T18:05:38.518797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.merge(df_train.iloc[:, :5], pd.DataFrame(pred_sub), how='inner', left_index=True, right_index=True)\ndf_submission = df_submission.rename(columns={\n    0: 'SEMANA_51', \n    1: 'SEMANA_52',\n    2: 'SEMANA_53',\n    3: 'SEMANA_54',\n    4: 'SEMANA_55',\n    5: 'SEMANA_56',\n    6: 'SEMANA_57',\n    7: 'SEMANA_58',\n    8: 'SEMANA_59',\n    9: 'SEMANA_60'\n})\n\ndf_submission['BASE_ID'] = df_submission['Z_MODELO'].astype(str) + '|' + df_submission['Z_PUNTO_VENTA'].astype(str) + '|' + df_submission['Z_GAMA'].astype(str)\ndf_submission = df_submission.iloc[:, 5:]\ndf_submission = df_submission.set_index('BASE_ID').stack().to_frame().reset_index()\ndf_submission['BASE_ID'] = df_submission['BASE_ID'].astype(str) + '|' + df_submission['level_1'].astype(str)\ndf_submission = df_submission.drop(['level_1'], axis=1)\ndf_submission.columns = ['ID', 'Demanda']","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:38.520429Z","iopub.status.idle":"2022-08-14T18:05:38.521097Z","shell.execute_reply.started":"2022-08-14T18:05:38.520854Z","shell.execute_reply":"2022-08-14T18:05:38.520883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('entel_cnn_v10.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:38.523148Z","iopub.status.idle":"2022-08-14T18:05:38.523548Z","shell.execute_reply.started":"2022-08-14T18:05:38.523359Z","shell.execute_reply":"2022-08-14T18:05:38.523378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = 0.9999\nprint(df_submission.Demanda.quantile(p))\nprint(pd.DataFrame(y_train).stack().quantile(p))\n# 76.832","metadata":{"execution":{"iopub.status.busy":"2022-08-14T18:05:38.524775Z","iopub.status.idle":"2022-08-14T18:05:38.525629Z","shell.execute_reply.started":"2022-08-14T18:05:38.525419Z","shell.execute_reply":"2022-08-14T18:05:38.525442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href='./entel_cnn_v10.csv'>download</a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}