{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:22.750795Z",
     "iopub.execute_input": "2022-08-17T08:29:22.751674Z",
     "iopub.status.idle": "2022-08-17T08:29:22.757457Z",
     "shell.execute_reply.started": "2022-08-17T08:29:22.751630Z",
     "shell.execute_reply": "2022-08-17T08:29:22.756345Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "CONFIG_KAGGLE = {\n",
    "    'TRAIN_PATH': '/kaggle/input/datathon-entel-2022-reto2/train.csv',\n",
    "    'TEST_PATH': '/kaggle/input/datathon-entel-2022-reto2/test.csv',\n",
    "    'SAMPLE_SUBMISSION': '/kaggle/input/datathon-entel-2022-reto2/test_sample.csv'\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    'TRAIN_PATH': '../data/train.csv',\n",
    "    'TEST_PATH': '../data/test.csv',\n",
    "    'SAMPLE_SUBMISSION': '../data/test_sample.csv'\n",
    "}\n",
    "\n",
    "df_train = pd.read_csv(CONFIG_KAGGLE['TRAIN_PATH'])\n",
    "df_test = pd.read_csv(CONFIG_KAGGLE['TEST_PATH'])\n",
    "df_sub = pd.read_csv(CONFIG_KAGGLE['SAMPLE_SUBMISSION'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:22.759688Z",
     "iopub.execute_input": "2022-08-17T08:29:22.760432Z",
     "iopub.status.idle": "2022-08-17T08:29:24.246266Z",
     "shell.execute_reply.started": "2022-08-17T08:29:22.760396Z",
     "shell.execute_reply": "2022-08-17T08:29:24.245257Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def featuring(df_train, df, x_base):\n",
    "    df = pd.concat([df_train.iloc[:, :5], df], axis=1)\n",
    "\n",
    "    df_z_punto_venta = df.groupby(['Z_PUNTO_VENTA'])[df.iloc[:, 5:].columns].transform('max')\n",
    "    df_z_modelo = df.groupby(['Z_MODELO'])[df.iloc[:, 5:].columns].transform('max')\n",
    "    df_z_gama = df.groupby(['Z_GAMA'])[df.iloc[:, 5:].columns].transform('max')\n",
    "    df_z_marca = df.groupby(['Z_MARCA'])[df.iloc[:, 5:].columns].transform('max')\n",
    "    df_z_departamento = df.groupby(['Z_DEPARTAMENTO'])[df.iloc[:, 5:].columns].transform('max')\n",
    "\n",
    "    df_z_s_punto_venta = df.groupby(['Z_PUNTO_VENTA'])[df.iloc[:, 5:].columns].transform('sum')\n",
    "    df_z_s_modelo = df.groupby(['Z_MODELO'])[df.iloc[:, 5:].columns].transform('sum')\n",
    "    df_z_s_gama = df.groupby(['Z_GAMA'])[df.iloc[:, 5:].columns].transform('sum')\n",
    "    df_z_s_marca = df.groupby(['Z_MARCA'])[df.iloc[:, 5:].columns].transform('sum')\n",
    "    df_z_s_departamento = df.groupby(['Z_DEPARTAMENTO'])[df.iloc[:, 5:].columns].transform('sum')\n",
    "\n",
    "    df_b_punto_venta = df['Z_PUNTO_VENTA'].apply(lambda x: 1 if x in\n",
    "                                                                [\n",
    "                                                                    'da45328ba820604eb99694768f2a430cd933d161601dcb8491b4a9b555232c59',\n",
    "                                                                    'e1f2d2708f545ddc1d7266ba0cc5ccc88147b77fdf3450e68a974e93018ecf60'] else 0)\n",
    "    df_b_departameto = df['Z_DEPARTAMENTO'].apply(lambda x: 1 if x in\n",
    "                                                                 [\n",
    "                                                                     'd6c21b948958417ca98b682a573eb8aa1084b292d32f760f253ef53da13e5589'] else 0)\n",
    "\n",
    "    Z_MARCA = df['Z_MARCA'].replace(df['Z_MARCA'].value_counts(normalize=True).to_dict())\n",
    "    Z_GAMA = df['Z_GAMA'].replace(df['Z_GAMA'].value_counts(normalize=True).to_dict())\n",
    "    Z_MODELO = df['Z_MODELO'].replace(df['Z_MODELO'].value_counts(normalize=True).to_dict())\n",
    "    Z_DEPARTAMENTO = df['Z_DEPARTAMENTO'].replace(df['Z_DEPARTAMENTO'].value_counts(normalize=True).to_dict())\n",
    "    Z_PUNTO_VENTA = df['Z_PUNTO_VENTA'].replace(df['Z_PUNTO_VENTA'].value_counts(normalize=True).to_dict())\n",
    "\n",
    "    df_max = df.iloc[:, 5:].max(axis=1)\n",
    "    df_sum = df.iloc[:, 5:].sum(axis=1)\n",
    "    df_std = df.iloc[:, 5:].std(axis=1)\n",
    "    df_mean = df.iloc[:, 5:].mean(axis=1)\n",
    "\n",
    "    df_total = df_sum.apply(lambda x: 1 if x > 0 else 0)\n",
    "    df_count = df.iloc[:, 5:].stack().apply(lambda x: x if x > 0 else np.nan).unstack(level=1).count(axis=1)\n",
    "\n",
    "    features = df.iloc[:, 5:].stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1)\n",
    "\n",
    "    df_z = pd.concat([\n",
    "        features,\n",
    "        df_z_punto_venta,\n",
    "        df_z_modelo,\n",
    "        df_z_gama,\n",
    "        df_z_marca,\n",
    "        df_z_departamento,\n",
    "\n",
    "        df_z_s_punto_venta,\n",
    "        df_z_s_modelo,\n",
    "        df_z_s_gama,\n",
    "        df_z_s_marca,\n",
    "        df_z_s_departamento,\n",
    "\n",
    "        df_b_punto_venta,\n",
    "        df_b_departameto,\n",
    "\n",
    "        Z_MARCA,\n",
    "        Z_GAMA,\n",
    "        Z_MODELO,\n",
    "        Z_DEPARTAMENTO,\n",
    "        Z_PUNTO_VENTA,\n",
    "\n",
    "        df_max,\n",
    "        df_sum,\n",
    "        df_std,\n",
    "        df_mean,\n",
    "\n",
    "        df_total,\n",
    "        df_count\n",
    "\n",
    "    ], axis=1).T.reset_index(drop=True).T\n",
    "\n",
    "    return df_z"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.247926Z",
     "iopub.execute_input": "2022-08-17T08:29:24.248768Z",
     "iopub.status.idle": "2022-08-17T08:29:24.266919Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.248718Z",
     "shell.execute_reply": "2022-08-17T08:29:24.265805Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def data_sequence_to_models(x_train, x_test, n):\n",
    "    correlated_features = set()\n",
    "    correlation_matrix = x_train.iloc[:, n:].corr()\n",
    "\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "\n",
    "    x_train_model = x_train.drop(labels=correlated_features, axis=1)\n",
    "    x_test_model = x_test.drop(labels=correlated_features, axis=1)\n",
    "\n",
    "    print(f'TRAIN SHAPE: {x_train_model.shape}')\n",
    "\n",
    "    sc = RobustScaler()\n",
    "    _x_train = sc.fit_transform(x_train_model)\n",
    "    _x_test = sc.transform(x_test_model)\n",
    "\n",
    "    return _x_train, _x_test\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.270127Z",
     "iopub.execute_input": "2022-08-17T08:29:24.270430Z",
     "iopub.status.idle": "2022-08-17T08:29:24.281765Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.270385Z",
     "shell.execute_reply": "2022-08-17T08:29:24.280723Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def eval_model(model, x_valid, y_valid):\n",
    "    preds = pd.DataFrame(np.round(model.predict(x_valid)).astype('int32')).stack().reset_index(drop=True)\n",
    "    y_valid = pd.DataFrame(y_valid).stack().reset_index(drop=True)\n",
    "    print(f' RMSE --> {mean_squared_error(y_valid, preds, squared=False)}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.283108Z",
     "iopub.execute_input": "2022-08-17T08:29:24.283523Z",
     "iopub.status.idle": "2022-08-17T08:29:24.291769Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.283489Z",
     "shell.execute_reply": "2022-08-17T08:29:24.290805Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCH = 1000\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "\n",
    "def data(x_train_data, y_train, t_idx, v_idx, model_type, n=0):\n",
    "    if model_type == 'mlp':\n",
    "        _x_train, _x_valid = x_train_data[t_idx], x_train_data[v_idx]\n",
    "\n",
    "        _y_train, _y_valid = y_train[t_idx], y_train[v_idx]\n",
    "\n",
    "        model = mlp(_x_train.shape[-1])\n",
    "\n",
    "        return [_x_train], [_x_valid], _y_train, _y_valid, model\n",
    "\n",
    "    if model_type == 'lstm':\n",
    "        _x_train, _x_valid = x_train_data[t_idx], x_train_data[v_idx]\n",
    "\n",
    "        x_t_features, x_v_features = _x_train[:, :n], _x_valid[:, :n]\n",
    "        x_t_features = np.reshape(x_t_features, (x_t_features.shape[0], x_t_features.shape[1], 1))\n",
    "        x_v_features = np.reshape(x_v_features, (x_v_features.shape[0], x_v_features.shape[1], 1))\n",
    "\n",
    "        x_t_extras, x_v_extras = _x_train[:, n:], _x_valid[:, n:]\n",
    "\n",
    "        _y_train, _y_valid = y_train[t_idx], y_train[v_idx]\n",
    "\n",
    "        l_fet = x_t_features.shape[-2:]\n",
    "        l_ext = x_t_extras.shape[-1]\n",
    "\n",
    "        model = lstm(l_fet, l_ext)\n",
    "\n",
    "        return [x_t_features, x_t_extras], [x_v_features, x_v_extras], _y_train, _y_valid, model\n",
    "\n",
    "\n",
    "def training(model_type, x_train_data, y_train, n):\n",
    "    \"\"\"\n",
    "    :param n: n define the number of column to use for lstm or cnn\n",
    "    :param y_train: numpy array\n",
    "    :param x_train_data: numpy array\n",
    "    :param model_type: str type: could be lstm, cnn or mlp\n",
    "    :return: list of tensorflow models\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "\n",
    "    y_group = pd.Series(y_train.sum(axis=1)).apply(lambda x: x if x < 15 else 15).values\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(x_train_data, y_group)):\n",
    "        print('-' * 15, '>', f'Fold {fold + 1}', '<', '-' * 15)\n",
    "\n",
    "        _x_train, _x_valid, _y_train, _y_valid, model = data(x_train_data, y_train, train_idx, val_idx, model_type, n)\n",
    "        \n",
    "        es = keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error',\n",
    "                                   min_delta=1e-05,\n",
    "                                   patience=30,\n",
    "                                   verbose=1,\n",
    "                                   mode='min',\n",
    "                                   restore_best_weights=True)\n",
    "        \n",
    "        plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_root_mean_squared_error',\n",
    "                                            factor=0.1,\n",
    "                                            patience=10,\n",
    "                                            verbose=1,\n",
    "                                            min_lr=5e-7,\n",
    "                                            mode='min')\n",
    "\n",
    "        model.fit(_x_train, _y_train,\n",
    "                  validation_data=(_x_valid, _y_valid),\n",
    "                  epochs=EPOCH,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  callbacks=[es, plateau],\n",
    "                  verbose=1)\n",
    "\n",
    "        eval_model(model, _x_valid, _y_valid)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    return models\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.293342Z",
     "iopub.execute_input": "2022-08-17T08:29:24.293725Z",
     "iopub.status.idle": "2022-08-17T08:29:24.309657Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.293691Z",
     "shell.execute_reply": "2022-08-17T08:29:24.308646Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def lstm(l_features, l_extras_features):\n",
    "    features = keras.layers.Input(shape=l_features)\n",
    "    tabular = keras.layers.Input(shape=l_extras_features)\n",
    "\n",
    "    out_features = keras.layers.LSTM(250, return_sequences=True)(features)\n",
    "    out_features = keras.layers.Dropout(0.2)(out_features)\n",
    "    out_features = keras.layers.LSTM(150, return_sequences=True)(out_features)\n",
    "    out_features = keras.layers.Dropout(0.2)(out_features)\n",
    "    out_features = keras.layers.LSTM(100)(out_features)\n",
    "    out_features = keras.layers.Flatten()(out_features)\n",
    "\n",
    "    out_features = keras.layers.Dense(50, activation='linear')(out_features)\n",
    "    out_features = keras.layers.Dropout(0.2)(out_features)\n",
    "    out_features = keras.layers.Dense(32, activation='linear')(out_features)\n",
    "\n",
    "    for n_hidden in [512, 256, 128, 64, 32]:\n",
    "        out_tabular = keras.layers.Dense(n_hidden, activation='relu')(tabular)\n",
    "        out_tabular = keras.layers.BatchNormalization()(out_tabular)\n",
    "        out_tabular = keras.layers.Dropout(0.2)(out_tabular)\n",
    "\n",
    "    out = keras.layers.Multiply()([out_features, out_tabular])\n",
    "    out = keras.layers.Dense(10, activation='relu')(out)\n",
    "\n",
    "    model = keras.Model(inputs=[features, tabular], outputs=out)\n",
    "\n",
    "    mse = keras.losses.MeanSquaredError()\n",
    "    rmse = keras.metrics.RootMeanSquaredError()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0004), loss=mse, metrics=[rmse])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def mlp(l_extras_features):\n",
    "    tabular = keras.layers.Input(shape=l_extras_features)\n",
    "\n",
    "    for n_hidden in [1024, 512, 256, 128, 64, 32]:\n",
    "        out_tabular = keras.layers.Dense(n_hidden, activation='linear')(tabular)\n",
    "        out_tabular = keras.layers.BatchNormalization()(out_tabular)\n",
    "        out_tabular = keras.layers.Dropout(0.2)(out_tabular)\n",
    "\n",
    "    out = keras.layers.Dense(10, activation='relu')(out_tabular)\n",
    "\n",
    "    model = keras.Model(inputs=[tabular], outputs=out)\n",
    "\n",
    "    mse = keras.losses.MeanSquaredError()\n",
    "    rmse = keras.metrics.RootMeanSquaredError()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0004), loss=mse, metrics=[rmse])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.311172Z",
     "iopub.execute_input": "2022-08-17T08:29:24.311656Z",
     "iopub.status.idle": "2022-08-17T08:29:24.326313Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.311604Z",
     "shell.execute_reply": "2022-08-17T08:29:24.325272Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def lstm_test_csv(x_test, models, n, name):\n",
    "    predictions = []\n",
    "\n",
    "    x_test_features = x_test[:, :n]\n",
    "    x_test_features = np.reshape(x_test_features, (x_test_features.shape[0], x_test_features.shape[1], 1))\n",
    "\n",
    "    x_test_extras = x_test[:, n:]\n",
    "\n",
    "    for model in models:\n",
    "        _pred = model.predict([x_test_features, x_test_extras])\n",
    "        predictions.append(_pred)\n",
    "        \n",
    "        \n",
    "    sub_predictions = (predictions[0] + predictions[1] + predictions[2] + predictions[3] + predictions[4]) / 5\n",
    "\n",
    "\n",
    "    result_to_csv(sub_predictions, name)\n",
    "\n",
    "\n",
    "def mlp_test_csv(x_test, models, n, name):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        _pred = model.predict([x_test])\n",
    "        predictions.append(_pred)\n",
    "        \n",
    "    sub_predictions = (predictions[0] + predictions[1] + predictions[2] + predictions[3] + predictions[4]) / 5\n",
    "\n",
    "    result_to_csv(sub_predictions, name)\n",
    "\n",
    "\n",
    "def result_to_csv(predictions, name):\n",
    "    df_submission = pd.merge(df_train.iloc[:, :5],\n",
    "                             pd.DataFrame(predictions),\n",
    "                             how='inner',\n",
    "                             left_index=True,\n",
    "                             right_index=True)\n",
    "\n",
    "    df_submission = df_submission.rename(columns={\n",
    "        0: 'SEMANA_51',\n",
    "        1: 'SEMANA_52',\n",
    "        2: 'SEMANA_53',\n",
    "        3: 'SEMANA_54',\n",
    "        4: 'SEMANA_55',\n",
    "        5: 'SEMANA_56',\n",
    "        6: 'SEMANA_57',\n",
    "        7: 'SEMANA_58',\n",
    "        8: 'SEMANA_59',\n",
    "        9: 'SEMANA_60'\n",
    "    })\n",
    "\n",
    "    df_submission['BASE_ID'] = df_submission['Z_MODELO'].astype(str) + '|' + \\\n",
    "                               df_submission['Z_PUNTO_VENTA'].astype(str) + '|' + \\\n",
    "                               df_submission['Z_GAMA'].astype(str)\n",
    "\n",
    "    df_submission = df_submission.iloc[:, 5:]\n",
    "\n",
    "    df_submission = df_submission.set_index('BASE_ID').stack().to_frame().reset_index()\n",
    "    df_submission['BASE_ID'] = df_submission['BASE_ID'].astype(str) + '|' + df_submission['level_1'].astype(str)\n",
    "\n",
    "    df_submission = df_submission.drop(['level_1'], axis=1)\n",
    "    df_submission.columns = ['ID', 'Demanda']\n",
    "\n",
    "    df_submission.to_csv(f'{name}.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.329690Z",
     "iopub.execute_input": "2022-08-17T08:29:24.330395Z",
     "iopub.status.idle": "2022-08-17T08:29:24.342478Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.330362Z",
     "shell.execute_reply": "2022-08-17T08:29:24.341523Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODELOS LSTM"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def model_lstm_based_40():\n",
    "    n = 40\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = featuring(df_train, df_train.iloc[:, 5:45], x_base)\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 15:55], x_base)\n",
    "\n",
    "    y_train = df_train.iloc[:, 45:55]\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('lstm', x_train_data, y_train, n)\n",
    "\n",
    "    lstm_test_csv(x_test_data, models, n, 'lstm_40')\n",
    "\n",
    "\n",
    "def model_lstm_based_20():\n",
    "    n = 20\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = pd.concat([\n",
    "        featuring(df_train, df_train.iloc[:, 5:25], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 15:35], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 25:45], x_base),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    y_train = pd.concat([\n",
    "        pd.DataFrame(df_train.iloc[:, 25:35].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 35:45].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 45:55].values),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 35:55], x_base)\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('lstm', x_train_data, y_train, n)\n",
    "\n",
    "    lstm_test_csv(x_test_data, models, n, 'lstm_20')\n",
    "    \n",
    "def model_lstm_based_10():\n",
    "    n = 10\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = pd.concat([\n",
    "        featuring(df_train, df_train.iloc[:, 5:15], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 15:25], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 25:35], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 35:45], x_base),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    y_train = pd.concat([\n",
    "        pd.DataFrame(df_train.iloc[:, 15:25].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 25:35].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 35:45].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 45:55].values)\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 45:55], x_base)\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('lstm', x_train_data, y_train, n)\n",
    "\n",
    "    lstm_test_csv(x_test_data, models, n, 'lstm_10')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.345771Z",
     "iopub.execute_input": "2022-08-17T08:29:24.346197Z",
     "iopub.status.idle": "2022-08-17T08:29:24.363487Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.346152Z",
     "shell.execute_reply": "2022-08-17T08:29:24.362333Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_lstm_based_40()\n",
    "model_lstm_based_20()\n",
    "model_lstm_based_10()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T08:29:24.368099Z",
     "iopub.execute_input": "2022-08-17T08:29:24.368491Z",
     "iopub.status.idle": "2022-08-17T09:14:05.073688Z",
     "shell.execute_reply.started": "2022-08-17T08:29:24.368463Z",
     "shell.execute_reply": "2022-08-17T09:14:05.071875Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelos MLP"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def model_mlp_based_40():\n",
    "    n = 0\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = pd.concat([\n",
    "        featuring(df_train, df_train.iloc[:, 5:25], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 15:35], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 25:45], x_base),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    y_train = pd.concat([\n",
    "        pd.DataFrame(df_train.iloc[:, 25:35].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 35:45].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 45:55].values),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 35:55], x_base)\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('mlp', x_train_data, y_train, n)\n",
    "\n",
    "    mlp_test_csv(x_test_data, models, n, 'mlp_40')\n",
    "\n",
    "\n",
    "def model_mlp_based_20():\n",
    "    n = 0\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = pd.concat([\n",
    "        featuring(df_train, df_train.iloc[:, 5:15], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 15:25], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 25:35], x_base),\n",
    "        featuring(df_train, df_train.iloc[:, 35:45], x_base),\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    y_train = pd.concat([\n",
    "        pd.DataFrame(df_train.iloc[:, 15:25].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 25:35].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 35:45].values),\n",
    "        pd.DataFrame(df_train.iloc[:, 45:55].values)\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 45:55], x_base)\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('mlp', x_train_data, y_train, n)\n",
    "\n",
    "    mlp_test_csv(x_test_data, models, n, 'mlp_20')\n",
    "\n",
    "\n",
    "def model_mlp_based_10():\n",
    "    n = 0\n",
    "    x_base = 100\n",
    "\n",
    "    x_train = featuring(df_train, df_train.iloc[:, 5:45], x_base)\n",
    "    x_test = featuring(df_train, df_train.iloc[:, 15:55], x_base)\n",
    "\n",
    "    y_train = df_train.iloc[:, 45:55]\n",
    "\n",
    "    x_train_data, x_test_data = data_sequence_to_models(x_train, x_test, n)\n",
    "\n",
    "    y_train = y_train.stack().apply(lambda x: x if x < x_base else x_base).unstack(level=1).values\n",
    "\n",
    "    models = training('mlp', x_train_data, y_train, n)\n",
    "\n",
    "    mlp_test_csv(x_test_data, models, n, 'mlp_10')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:08.005998Z",
     "iopub.execute_input": "2022-08-17T09:14:08.006438Z",
     "iopub.status.idle": "2022-08-17T09:14:08.024838Z",
     "shell.execute_reply.started": "2022-08-17T09:14:08.006404Z",
     "shell.execute_reply": "2022-08-17T09:14:08.023807Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_mlp_based_40()\n",
    "model_mlp_based_20()\n",
    "model_mlp_based_10()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:08.558169Z",
     "iopub.execute_input": "2022-08-17T09:14:08.558703Z",
     "iopub.status.idle": "2022-08-17T09:23:14.182456Z",
     "shell.execute_reply.started": "2022-08-17T09:14:08.558649Z",
     "shell.execute_reply": "2022-08-17T09:23:14.180761Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Integración"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_train.iloc[:, 45:55].stack().to_frame().rename(columns={0: 'Demanda'}).to_csv('entel_last.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:05.079728Z",
     "iopub.status.idle": "2022-08-17T09:14:05.080907Z",
     "shell.execute_reply.started": "2022-08-17T09:14:05.080620Z",
     "shell.execute_reply": "2022-08-17T09:14:05.080644Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "r1 = pd.read_csv('lstm_40.csv')\n",
    "r2 = pd.read_csv('lstm_20.csv')\n",
    "r3 = pd.read_csv('lstm_10.csv')\n",
    "\n",
    "r1['Demanda'] = r1['Demanda'] * 0.30 + r2['Demanda'] * 0.50 + r3['Demanda'] * 0.2\n",
    "\n",
    "r1.to_csv('lstm_final.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:05.082149Z",
     "iopub.status.idle": "2022-08-17T09:14:05.083004Z",
     "shell.execute_reply.started": "2022-08-17T09:14:05.082719Z",
     "shell.execute_reply": "2022-08-17T09:14:05.082743Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "r1 = pd.read_csv('mlp_40.csv')\n",
    "r2 = pd.read_csv('mlp_20.csv')\n",
    "r3 = pd.read_csv('mlp_10.csv')\n",
    "\n",
    "r1['Demanda'] = r1['Demanda'] * 0.30 + r2['Demanda'] * 0.50 + r3['Demanda'] * 0.2\n",
    "\n",
    "r1.to_csv('mlp_final.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:05.084559Z",
     "iopub.status.idle": "2022-08-17T09:14:05.085490Z",
     "shell.execute_reply.started": "2022-08-17T09:14:05.085234Z",
     "shell.execute_reply": "2022-08-17T09:14:05.085258Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "r1 = pd.read_csv('lstm_final.csv')\n",
    "r2 = pd.read_csv('mlp_final.csv')\n",
    "r3 = pd.read_csv('entel_last.csv')\n",
    "\n",
    "r1['Demanda'] = np.round(r1['Demanda'] * 0.50 + \\\n",
    "                         r2['Demanda'] * 0.30 + \\\n",
    "                         r3['Demanda'] * 0.20)\n",
    "\n",
    "r1.to_csv('entel_final.csv', index=False)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-17T09:14:05.087134Z",
     "iopub.status.idle": "2022-08-17T09:14:05.087990Z",
     "shell.execute_reply.started": "2022-08-17T09:14:05.087706Z",
     "shell.execute_reply": "2022-08-17T09:14:05.087730Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}